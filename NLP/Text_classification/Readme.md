# Project: Text classification

__Approach:__

Text classification in the field of natural language processing may be considered as a well-explored task with an established solution. Such a solution could be summaries into employ a BERT-family models to classify a text. However, the recent emerge in employ out-of-domeain training, and also enhance model performace via improving the embedding part of the model boost the performance of traditional models. Employ the new approaches and add several modification to the BERT-family model, the goal of this project is to classifiy a document and achive higher accuracy, compare with any existing off-the-shelves pre-trained NLP model.
In the second phase of the project, a distilled version of the model, with some extra modification is developed to run the model on a system with CPU only. 


